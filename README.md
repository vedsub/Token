# Token ğŸ¤–

A collection of LLM experiments including prompting techniques, RAG systems, and AI agents.

## ğŸ“‹ Overview

| Module | Description |
|--------|-------------|
| `prompts/` | Zero-shot, Chain of Thought, Few-shot prompting |
| `rag/` | RAG system with PDF indexing using Qdrant |
| `rag_queue/` | Async RAG API with HuggingFace + FastAPI |
| `lang_graph/` | LangGraph with conditional edges & smart routing |
| `weather_agent/` | AI agent with tool calling |
| `ollama-fastapi/` | Local LLM API server |

## ğŸ—‚ï¸ Project Structure

```
tokenise/
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ zero.py          # Zero-shot prompting
â”‚   â”œâ”€â”€ cot.py           # Chain of Thought with chat
â”‚   â””â”€â”€ few.py           # Few-shot prompting
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ index.py         # PDF indexing to Qdrant
â”‚   â””â”€â”€ chat.py          # RAG chat interface
â”œâ”€â”€ rag_queue/
â”‚   â”œâ”€â”€ server.py        # FastAPI server with background tasks
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ lang_graph/
â”‚   â””â”€â”€ chat.py          # Conditional edges & smart routing
â”œâ”€â”€ weather_agent/
â”‚   â”œâ”€â”€ agent.py         # AI agent with tools
â”‚   â””â”€â”€ main.py
â””â”€â”€ ollama-fastapi/
    â””â”€â”€ server.py        # Ollama API server
```

## ğŸš€ Quick Start

### 1. Setup

```bash
git clone https://github.com/vedsub/Token.git
cd Token
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env  # Add your API keys
```

### 2. RAG Queue API (HuggingFace)

```bash
# Start services
cd rag_queue
docker-compose up -d

# Index your PDF
cd ../rag
python index.py

# Start API
cd ../rag_queue
uvicorn server:app --host 0.0.0.0 --port 8000
```

**Endpoints:**
- `POST /chat` - Submit a query (returns job_id)
- `GET /status/{job_id}` - Get result
- `GET /docs` - Swagger UI

### 3. Prompting Examples

```bash
python prompts/cot.py   # Interactive CoT chat
python prompts/zero.py  # Zero-shot example
```

### 4. LangGraph (Conditional Routing)

```bash
cd lang_graph
python chat.py
```

**Routing Logic:**
- Messages with "help" or "?" â†’ Help Node
- Messages with "joke" â†’ Joke Node
- Default â†’ Chatbot Node

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| LLM (Cloud) | HuggingFace (Qwen2.5-72B), Google Gemini |
| LLM (Local) | Ollama (Gemma 3) |
| Graph Framework | LangGraph |
| Vector DB | Qdrant |
| Embeddings | HuggingFace (all-MiniLM-L6-v2) |
| API | FastAPI |
| Queue | Valkey (Redis-compatible) |

## ğŸ“ Environment Variables

```env
HUGGINGFACE_TOKEN=your_hf_token
GEMINI_API_KEY=your_gemini_key
OPENAI_API_KEY=your_openai_key
```

## ğŸ“„ License

MIT License
